{"/prompts.docs/projects/vscode/":{"data":{"background#Background":"BackgroundWe worked on a VSCode extension to add a new Docker Language Service. The language sevice is IDE agnostic and can be attached to IDEs like Intellij, and neovim.\nThe current extension releases are available internally to Docker employees."},"title":"vscode"},"/prompts.docs/tools/":{"data":{"":"","background#Background":"The mcp/run container is an mcp server that can be extended with new container-based tools, and prompts. Existing containers, like curl or ffmpeg, can now be exposed as MCP servers without having to wrap each tool in an mcp server.\nflowchart LR desktop[\"Claude Desktop\"] subgraph docker[\"Docker\"] mcp[\"mcp/docker\"] end desktop --\u003e docker docker -- extended by --- box1[\"Tools/Prompt Def (curl)\"] docker -- extended by --- box2[\"Tools/Prompt Def (ffmpeg)\"] style desktop fill:#f9f9f9,stroke:#333,stroke-width:2px style docker fill:#e6f3ff,stroke:#333,stroke-width:2px,color:#0066cc style mcp fill:#fff,stroke:#333,stroke-width:1px style box1 fill:#f9f9f9,stroke:#333,stroke-width:2px style box2 fill:#f9f9f9,stroke:#333,stroke-width:2pxDefinitions of new tools and prompts are made using markdown documents (see examples).\n--- tools: - name: curl --- # prompt Run the curl command, in silent mode, to fetch gists for user slimslenderslacks from GitHub. ","getting-started#Getting Started":"We can use this to extend MCP clients like Claude Desktop, and test new tool definitions using VSCode. Instructions for these two paths are here.\nAttach the MCP server to Claude Desktop. Claude Desktop has not yet implemented the notifications/tools/list_changed. This means that Claude doesn’t reload our tool definitions until it is restarted. It’s easier to develop prompts in VSCode where we can create a much more efficient inner loop. Test prompt definitions using our VSCode extension. Using VSCode as an mcp server can provide an effective inner loop for developing the content. "},"title":"MCP/docker Toolbox"},"/prompts.docs/tools/docs/":{"data":{"":"","#":"Topics How to author prompts Updating Claude Desktop "},"title":"Documentation"},"/prompts.docs/tools/docs/authoring-prompts/":{"data":{"models#Models":"If you don’t specify a model in the preamble, the default model is currently set to be gpt-4 on openai. You can refer to other models and other endpoints using model and url.\n--- tools: - name: curl model: claude-3-5-sonnet-20241022 --- # prompt Run the curl command, in silent mode, to fetch gists for user slimslenderslacks from GitHub. If you specify an anthropic model, such as model: claude-3-5-sonnet-20241022, you do not need to specify the url. The correct anthropic endpoint will be used.\nℹ️ When using anthropic, do not change tool definitions to use json_schema. Use the openai standard of parameters - this will be automatically converted before making the api call. OpenAI-compatible endpoints (Ollama) You can specify other openai-compatible endpoints by including a url.\n--- tools: - name: curl url: http://localhost/v1/chat/completions stream: false model: llama3.1 --- # prompt Run the curl command, in silent mode, to fetch gists for user slimslenderslacks from GitHub. ℹ️ Set streaming to false if you’re using Ollama for tool calling. Ollama does not currently stream tool calls. ","prompt-files#Prompt files":"Prompt filesA prompt is markdown content with a preamble describing tools available to the agent when executing this prompt.\nWe use h1 headers to delineate sections that should be exposed as prompts. When authoring this markdown, you can include non-prompt sections using headers that don’t start with the word “prompt”.\nHere’s a simple prompt that will use Docker official curl container to fetch gists from Github.\n--- tools: - name: curl --- # prompt Run the curl command, in silent mode, to fetch gists for user slimslenderslacks from GitHub. ","prompt-templates#Prompt Templates":"It is common for prompts to contain parameters that are either extracted from a user interaction or, in the case of RAG, are populated by some sort of retrieval process. Markdown prompts can also contain template parameters.\nFor example, the above curl example could be re-written as a template with a {{ user }} parameter.\n--- tools: - name: curl url: http://localhost/v1/chat/completions stream: false model: llama3.1 --- # prompt Run the curl command, in silent mode, to fetch gists for user {{ user }} from GitHub. Binding values during testing When running in VSCode, you can set values of the parameters in the markdown preamble.\n--- parameter-values: user: slimslenderslacks --- Extractors Extractors are container functions that can be used to extract values when the prompt has been deployed to a server. These extractors are also used to populate default values for a prompt when it is used from an MCP client.\nExtractor definitions also follow the pattern of compose services. They are just docker images but with the additional requirement that they should write application/json to stdout. This json will be used to populate the context for binding parameters in the prompt template.\n--- extractors: - name: linguist image: vonwig/go-linguist:latest command: - -json --- We can create lists if the extractor json output has array types. For example, if we run the linguist tool to extract language from a project, our prompt can list them using the following template. You need to be familar with the json format output by linguist (eg that it creates lists of maps with a language key).\n--- extractors: - name: linguist --- # prompt {{#linguist}} This project contains {{language}} code. {{/linguist}} Template Engine We support two templating engines today.\nmustache is the default django If you want to use django, then add the following field in the markdown preamble.\n--- prompt-format: \"django\" --- MCP arguments ","tools#Tools":"Some tools, like curl, are available by default. However, the container for a tool can also be defined inline.\n--- tools: - name: ffmpeg description: run the ffmpeg command parameters: type: object properties: args: description: arguments to pass to ffmpeg type: array items: type: string container: image: linuxserver/ffmpeg:version-7.1-cli command: - \"{{args|into}}\" --- # prompt Use ffmpeg to convert the file UsingPuppeteer.mp4 into an animated gif file at 1 frame per second. The output file should be named UsingPuppeteer.gif. The name, description, and container fields are mandatory, and you’ll typically also have a parameters field to descript the json schema of the parameters that the agent will extract from the conversation.\nname should uniquely identify the tool. description is important. Good descriptions help the agent understand the tool and how to use it. container sticks close to the format of a compose service definition but does fully implement it. Many of the most common top-level arguments are supported (image, command, volumes) You can interpolate into parameter properties into the container definition using strings with double curly braces. These substitutions also support filters, such as into, which spreads an array parameter. There are some common patterns for moving parameters into the container runtime that we support for making it easier to use standard images."},"title":"Authoring Prompts"},"/prompts.docs/tools/docs/claude-desktop/":{"data":{"":"Enable mcp_run in your claude_desktop_config.json file using the following snippet. See the quickstart for Claude Desktop Users for more details.\n{ \"mcpServers\": { \"mcp_run\": { \"command\": \"docker\", \"args\": [ \"run\", \"--rm\", \"-i\", \"--pull\", \"always\", \"-v\", \"/var/run/docker.sock:/var/run/docker.sock\", \"--mount\", \"type=volume,source=docker-prompts,target=/prompts\", \"vonwig/prompts:latest\", \"serve\", \"--mcp\", \"--register\", \"github:docker/labs-ai-tools-for-devs?path=prompts/examples/hello_world.md\" ] } } Notice in the above snippet that the server is loaded with one example prompt, which you can view in our public github repo. This will have already been exposed using this MCP server so when using Claude Desktop, you can type “use hello docker to greet me with a joke”.\nYou’ll see a prompt asking if you want to run the “hello world” tool locally.","more-prompts#More prompts":"You can register new definitions in public github repos by adding additional --register arguments.\n\"--register\", \"github:docker/labs-ai-tools-for-devs?path=prompts/examples/swagger.md\" We are moving these registration command to a command line. It doesn’t make sense to change the claude config each time you add or remote a defintion. However, because Claude Desktop has to be restarted every time a definition changes today (because of the missing notification), we will work with Anthropic to make this much smoother."},"title":"Using Claude Desktop"},"/prompts.docs/tools/examples/":{"data":{"":" simplest definition we can think of Use curl to fetch your GitHub gists call swagger api create an animaged gif using ffmpeg read and write local files use sqlite from an mcp client working with local files "},"title":"example prompts"},"/prompts.docs/tools/examples/curl/":{"data":{"description#Description":"DescriptionFetch gists from your user from GitHub","prompt-code#Prompt Code":" --- tools: - name: curl parameter-values: user: slimslenderslacks --- # prompt Run the curl command, in silent mode, to fetch gists for user {{user}} from GitHub. "},"title":"curl"},"/prompts.docs/tools/examples/ffmpeg/":{"data":{"description#Description":"DescriptionUse ffmpeg to convert an mp4 file to an animated gif.\nUsers must refer to the mp4 file using a relative path from the working directory they’ve given to the mcp bridge server.","prompt-code#Prompt Code":" --- tools: - name: ffmpeg description: run the ffmpeg command parameters: type: object properties: args: description: arguments to pass to ffmpeg type: array items: type: string container: image: linuxserver/ffmpeg:version-7.1-cli command: - \"{{args|into}}\" --- # prompt Use ffmpeg to convert the file UsingPuppeteer.mp4 into an animated gif file at 1 frame per second. The output file should be named UsingPuppeteer.gif. "},"title":"use ffmpeg"},"/prompts.docs/tools/examples/filesystem/":{"data":{"description#Description":"DescriptionAdd read_file and write_file tool containers.","prompt-code#Prompt Code":" --- model: claude-3-5-sonnet-20241022 tools: - name: read_file description: | read a file from disk Read the complete contents of a file from the file system. Handles various text encodings and provides detailed error messages if the file cannot be read. Use this tool when you need to examine the contents of a single file. Only works within allowed directories. parameters: type: object properties: path: type: string container: image: vonwig/bash_alpine entrypoint: cat command: - \"{{path|safe}}\" - name: write_file description: | Create a new file or completely overwrite an existing file with new content. Use with caution as it will overwrite existing files without warning. Handles text content with proper encoding. Only works within allowed directories. parameters: type: object properties: path: type: string content: type: string container: image: vonwig/bash_alpine command: - \"-c\" - \"echo {{content|safe}} \u003e {{path|safe}}\" --- # prompt user read the file deps.edn and then write the string \"blah.txt\" into the file test.txt "},"title":"filesystem"},"/prompts.docs/tools/examples/hello-world/":{"data":{"description#Description":"DescriptionJust echo a greeting by running a container!","prompt-code#Prompt Code":" --- name: hello-docker description: run the hello-docker model: claude-3-5-sonnet-20241022 tools: - name: hello-docker description: print a secret message container: image: busybox:latest command: - echo - \"Hello, World!\" --- # prompt Use hello world to print a secret message and then explain it to me "},"title":"hello world"},"/prompts.docs/tools/examples/sqlite/":{"data":{"description#Description":"DescriptionUse sqlite containers to provide 3 tools:\nread-query list-tables describe-table The sqlite database ( /mcp/test1.db ) is mounted using a Docker volume.\nUse these tools to ask Claude to explore the data using the tools above.\nHere’s a fully worked example for building insights from a user defined topic.","prompt-code#Prompt Code":" --- tools: - name: read-query description: Execute a SELECT query on the SQLite database parameters: type: object properties: query: type: string description: SELECT SQL query to execute container: \u0026sqlite-container image: \u0026sqlite-image vonwig/sqlite:latest command: - \u0026db \"/mcp/test1.db\" - \"{{query|safe}}\" volumes: \u0026mounts - \"mcp-test:/mcp\" - name: list-tables description: List all tables in the SQLite database container: image: *sqlite-image command: - *db - \"SELECT name from sqlite_master WHERE type='table'\" volumes: *mounts - name: describe-table description: Get the schema information for a specific table parameters: type: object properties: table_name: type: string description: Name of the table to describe container: image: *sqlite-image command: - *db - \"PRAGMA table_info({{table_name}})\" volumes: *mounts --- "},"title":"sqlite"},"/prompts.docs/tools/examples/swagger/":{"data":{"description#Description":"DescriptionDescribe a two step process where we first grab a swagger.json file from the web and then use that to make an api call.","prompt-code#Prompt Code":" --- tools: - name: curl --- # prompt Use curl to fetch the openai spec at https://fakerestapi.azurewebsites.net/swagger/v1/swagger.json Then use curl to get all authors from the api. "},"title":"call swagger api"},"/prompts.docs/tools/quickstart/":{"data":{"":"","#":" Install Configure Docker Desktop to use the mcp/run Docker container.\nRestart Claude Desktop Restarting desktop should be a one-time activity. However, Claude Desktop does not support the tools/list_changed notification so we currently have to restart desktop more less continuously. :)\nTry a prompt Write a prompt in Claude that will run one of the tools in a registered defintion. For example:\nUse hello world to send a greeting and then respond to what comes back."},"title":"Quick Start w/ Claude Desktop"},"/prompts.docs/tools/quickstart_vscode/":{"data":{"":"","#":" Download .vsix extension Download the .vsix extension from the releases page.\nInstall extension from .vsix file code --install-extension \u003cpath-to-vsix-file\u003e or use the VSCode command palette Extensions: Install from VSIX...\nOpen a prompt With the extension installed, open a prompt in VSCode. Examples can be found in the examples directory.\nConfigure OpenAI API Key, or use a different model. Default model is gpt-4 provided by OpenAI. Use an the VSCode command palette Docker AI: Set secret key to set your API key.\nChanging the model: Use the following keys in the prompt front-matter to change the model:\nAnthropic:\n--- model: claude-3-5-sonnet-20240620 --- Ollama:\n--- model: llama3.2 url: https://docker.host.internal:11434/v1 --- Run the prompt Use the VSCode command palette Docker AI: Run this prompt to run the prompt."},"title":"Quick Start w/ VSCode"}}